# Denoising Diffusion Probabilistic Models(DDPM)

## **摘要**

我们使用扩散概率模型（一类受非平衡热力学启发的潜变量模型）展示了高质量的图像合成结果。通过在加权变分界限上进行训练，我们得到了最佳结果，该界限是根据扩散概率模型与Langevin动力学去噪得分匹配之间的新连接设计的。此外，我们的模型自然支持一种渐进有损解压方案，可被解释为自回归解码的推广。在无条件CIFAR10数据集上，我们获得了9.46的Inception分数和3.17的最新FID分数。在256x256的LSUN数据集上，我们获得了与ProgressiveGAN相似的样本质量。我们的实现可在以下地址获得：[https://github.com/hojonathanho/diffusion](https://github.com/hojonathanho/diffusion)。

## 1. 引言

各种深度生成模型最近在多种数据模态上展示了高质量的样本。生成对抗网络（GANs）、自回归模型、流模型和变分自编码器（VAEs）已经合成了令人印象深刻的图像和音频样本[14, 27, 3, 58, 38, 25, 10, 32, 44, 57, 26, 33, 45]，而能量模型和得分匹配方面的显著进展也生成了与GANs相媲美的图像[11, 55]。本文介绍了在**扩散概率模型**[53]方面的进展。扩散概率模型（为简洁起见，我们称之为“扩散模型”）是一个参数化的马尔科夫链，通过变分推断进行训练，以便在有限时间后生成与数据相匹配的样本。这个链的转换是通过学习反向扩散过程来实现的，扩散过程是一个逐步向数据添加噪声的马尔科夫链，直到信号完全被破坏为止。当扩散过程由少量高斯噪声组成时，可以将采样链的转换设置为条件高斯，从而允许特别简单的神经网络参数化。

扩散模型定义起来简单且训练高效，但据我们所知，尚无证明其能够生成高质量样本的展示。我们展示了扩散模型实际上能够生成高质量样本，有时甚至优于其他类型生成模型的已发表结果（第4节）。此外，我们展示了一种扩散模型的参数化方法，这揭示了其与多噪声级别上的去噪得分匹配以及采样过程中的退火Langevin动力学之间的等价性（第3.2节）[55, 61]。我们使用这种参数化方法获得了最佳的样本质量结果（第4.2节），因此我们认为这一等价性是我们的主要贡献之一。

尽管我们的模型具有出色的样本质量，但其在对数似然方面不如其他基于似然的模型（然而，我们的模型的对数似然优于退火重要性采样为能量模型和得分匹配生成的估计结果[11, 55]）。我们发现，大多数模型的无损编码长度消耗在描述人眼不可察觉的图像细节上（第4.3节）。我们在有损压缩的语言下对此现象进行了更详细的分析，并展示了扩散模型的采样过程是一种渐进解码形式，类似于按位排序的自回归解码，这大大扩展了自回归模型通常可能实现的能力。

## 2. 背景

扩散模型[53] 是一种潜变量模型，其形式为 $p_\theta(x_0) := \int p_\theta(x_{0:T}) dx_{1:T}$，其中 $x_1, \dots, x_T$ 是与数据 $x_0 \sim q(x_0)$ 维度相同的潜变量。联合分布 $p_\theta(x_{0:T})$ 被称为**反向过程**，定义为从 $p(x_T) = N(x_T; 0, I)$ 开始的具有高斯转换的马尔科夫链：

$$
p_\theta(x_{0:T}) := p(x_T) \prod_{t=1}^{T} p_\theta(x_{t-1} | x_t), \quad p_\theta(x_{t-1} | x_t) := N(x_{t-1}; \mu_\theta(x_t, t), \Sigma_\theta(x_t, t))
\tag{1}
$$

与其他潜变量模型不同的是，扩散模型的近似后验 $q(x_{1:T} | x_0)$，即**正向过程**或**扩散过程**，被固定为一个马尔科夫链，该链根据方差计划 $\beta_1, \dots, \beta_T$ 逐步向数据中添加高斯噪声：

$$
q(x_{1:T} | x_0) := \prod_{t=1}^{T} q(x_t | x_{t-1}), \quad q(x_t | x_{t-1}) := N(x_t; \sqrt{1 - \beta_t} x_{t-1}, \beta_t I)
\tag{2}
$$

训练通过优化负对数似然的常规变分界限进行：

$$
\mathbb{E}[- \log p_\theta(x_0)] \leq \mathbb{E}_q \left[ - \log p_\theta(x_{0:T}) / q(x_{1:T} | x_0) \right]
= \mathbb{E}_q \left[ - \log p(x_T) - \sum_{t \geq 1} \log \frac{p_\theta(x_{t-1} | x_t)}{q(x_t | x_{t-1})} \right]
=: L
\tag{3}
$$

正向过程的方差 $\beta_t$ 可以通过重参数化学习[33]，也可以作为超参数保持不变。通过在 $p_\theta(x_{t-1} | x_t)$ 中选择高斯条件，确保了反向过程的表现力，因为当 $\beta_t$ 很小时，两个过程具有相同的函数形式[53]。正向过程的一个显著特性是，它允许在任意时间步 $t$ 对 $x_t$ 进行封闭形式采样：使用符号 $\alpha_t := 1 - \beta_t$ 和 $\bar{\alpha}_t := \prod_{s=1}^{t} \alpha_s$，我们得到：

$$
q(x_t | x_0) = N(x_t; \sqrt{\bar{\alpha}_t} x_0, (1 - \bar{\alpha}_t) I)
\tag{4}
$$

因此，可以通过使用随机梯度下降优化 $L$ 的随机项来实现高效训练。进一步的改进来自通过重写 $L$ (3) 来减少方差：

$$
\mathbb{E}_q \left[ D_{KL}(q(x_T | x_0) \| p(x_T)) + \sum_{t>1} D_{KL}(q(x_{t-1} | x_t, x_0) \| p_\theta(x_{t-1} | x_t)) - \log p_\theta(x_0 | x_1) \right]
\tag{5}
$$

（详见附录A，术语标注在第3节中使用。）公式(5)使用KL散度直接比较 $p_\theta(x_{t-1} | x_t)$ 和正向过程的后验，这些在条件为 $x_0$ 时是可解的：

$$
q(x_{t-1} | x_t, x_0) = N(x_{t-1}; \tilde{\mu}_t(x_t, x_0), \tilde{\beta}_t I),
\tag{6}
$$

其中

$$
\tilde{\mu}_t(x_t, x_0) := \frac{\sqrt{\bar{\alpha}_{t-1}} \beta_t}{1 - \bar{\alpha}_t} x_0 + \frac{\sqrt{\alpha_t} (1 - \bar{\alpha}_{t-1})}{1 - \bar{\alpha}_t} x_t, \quad \tilde{\beta}_t := \frac{1 - \bar{\alpha}_{t-1}}{1 - \bar{\alpha}_t} \beta_t
\tag{7}
$$

因此，公式(5)中的所有KL散度都是高斯分布之间的比较，因此可以使用封闭形式表达式进行Rao-Blackwell化计算，而不是高方差的蒙特卡洛估计。

## 3. 扩散模型与去噪自编码器

扩散模型可能看起来是受限的潜变量模型，但它们在实现中允许大量自由度。实现过程中需要选择正向过程的方差 $\beta_t$，以及反向过程的模型架构和高斯分布参数化。为了指导我们的选择，我们在第3.2节中建立了扩散模型与去噪得分匹配之间的新显式连接，从而引导我们为扩散模型提出了一个简化的加权变分边界目标（第3.4节）。最终，我们的模型设计通过简单性和实证结果得到了验证（第4节）。以下讨论按照公式(5)中的术语进行分类。

### 3.1 正向过程与 $L_T$

我们忽略正向过程的方差 $\beta_t$ 可通过重参数化学习这一事实，取而代之的是将它们固定为常数（详见第4节）。因此，在我们的实现中，近似后验 $q$ 没有可学习的参数，因此 $L_T$ 是训练过程中的常量，可以忽略不计。

### 3.2 反向过程与 $L_{1:T-1}$

现在我们讨论 $p_\theta(x_{t-1} | x_t) = N(x_{t-1}; \mu_\theta(x_t, t), \Sigma_\theta(x_t, t))$ 的选择，对于 $1 < t \leq T$，我们将 $\Sigma_\theta(x_t, t) = \sigma_t^2 I$ 设置为未训练的与时间相关的常数。实验表明，$\sigma_t^2 = \beta_t$ 和 $\sigma_t^2 = \tilde{\beta}_t = \frac{1 - \bar{\alpha}_{t-1}}{1 - \bar{\alpha}_t} \beta_t$ 产生了相似的结果。第一种选择对 $x_0 \sim N(0, I)$ 是最优的，第二种选择对 $x_0$ 固定为某一点是最优的。这两种极端选择对应于具有坐标单位方差的数据的反向过程熵的上下限[53]。

其次，为了表示均值 $\mu_\theta(x_t, t)$，我们提出了一种特定的参数化方法，该方法受到 $L_t$ 分析的启发。对于 $p_\theta(x_{t-1} | x_t) = N(x_{t-1}; \mu_\theta(x_t, t), \sigma_t^2 I)$，我们可以写出：

$$
L_{t-1} = \mathbb{E}_q \left[ \frac{1}{2 \sigma_t^2} \| \tilde{\mu}_t(x_t, x_0) - \mu_\theta(x_t, t) \|_2^2 \right] + C
\tag{8}
$$

其中，$C$ 是一个与 $\theta$ 无关的常数。因此，$\mu_\theta$ 最直接的参数化方式是预测 $\tilde{\mu}_t$，即正向过程的后验均值。然而，我们可以通过将公式(4)重参数化为 $x_t(x_0, \epsilon) = \sqrt{\bar{\alpha}_t} x_0 + \sqrt{1 - \bar{\alpha}_t} \epsilon$ 来进一步展开公式(8)，其中 $\epsilon \sim N(0, I)$，并应用正向过程后验公式(7)：

$$
L_{t-1} - C = \mathbb{E}_{x_0, \epsilon} \left[ \frac{1}{2 \sigma_t^2} \left\| \sqrt{\frac{1}{\alpha_t}} \left( x_t(x_0, \epsilon) - \frac{\beta_t}{\sqrt{1 - \bar{\alpha}_t}} \epsilon \right) - \mu_\theta(x_t(x_0, \epsilon), t) \right\|_2^2 \right]
\tag{10}
$$

**算法 1 训练**

1. 重复：
2. $x_0 \sim q(x_0)$
3. $t \sim \text{Uniform}(\{1, \dots, T\})$
4. $\epsilon \sim N(0, I)$
5. 对以下项进行梯度下降步骤：
$$
\left\| \epsilon - \epsilon_\theta \left( \sqrt{\bar{\alpha}_t} x_0 + \sqrt{1 - \bar{\alpha}_t} \epsilon, t \right) \right\|_2^2
$$
6. 直到收敛

**算法 2 采样**

1. $x_T \sim N(0, I)$
2. 对于 $t = T, \dots, 1$ 执行：
3. 若 $t > 1$，则 $z \sim N(0, I)$，否则 $z = 0$
4. 计算：
$$
x_{t-1} = \frac{1}{\sqrt{\alpha_t}} \left( x_t - \frac{1 - \alpha_t}{\sqrt{1 - \bar{\alpha}_t}} \epsilon_\theta(x_t, t) \right) + \sigma_t z
$$
5. 返回 $x_0$

公式(10)显示 $\mu_\theta$ 必须预测 $\sqrt{\frac{1}{\alpha_t}} \left( x_t - \frac{\beta_t}{\sqrt{1 - \bar{\alpha}_t}} \epsilon \right)$，因为 $x_t$ 是模型的输入，我们可以选择如下参数化：

$$
\mu_\theta(x_t, t) = \tilde{\mu}_t \left( x_t, \sqrt{\frac{1}{\bar{\alpha}_t}} \left( x_t - \sqrt{1 - \bar{\alpha}_t} \epsilon_\theta(x_t) \right) \right) = \sqrt{\frac{1}{\alpha_t}} \left( x_t - \frac{\beta_t}{\sqrt{1 - \bar{\alpha}_t}} \epsilon_\theta(x_t, t) \right)
\tag{11}
$$

其中，$\epsilon_\theta$ 是用于从 $x_t$ 预测 $\epsilon$ 的函数逼近器。为了从 $p_\theta(x_{t-1} | x_t)$ 采样 $x_{t-1}$，我们计算 $x_{t-1} = \frac{1}{\sqrt{\alpha_t}} \left( x_t - \frac{\beta_t}{\sqrt{1 - \bar{\alpha}_t}} \epsilon_\theta(x_t, t) \right) + \sigma_t z$，其中 $z \sim N(0, I)$。完整的采样过程如算法2所示，类似于使用 $\epsilon_\theta$ 作为数据密度的学习梯度的Langevin动力学。此外，使用参数化(11)，公式(10)简化为：

$$
\mathbb{E}_{x_0, \epsilon} \left[ \frac{\beta_t^2}{2 \sigma_t^2 \alpha_t (1 - \bar{\alpha}_t)} \left\| \epsilon - \epsilon_\theta \left( \sqrt{\bar{\alpha}_t} x_0 + \sqrt{1 - \bar{\alpha}_t} \epsilon, t \right) \right\|_2^2 \right]
\tag{12}
$$

这类似于多个噪声尺度（由 $t$ 索引）的去噪得分匹配[55]。由于公式(12)等于Langevin样式反向过程(11)的变分界限的一项，因此优化类似于去噪得分匹配的目标等价于使用变分推断来拟合类似于Langevin动力学的采样链的有限时间边缘。

总结来说，我们可以训练反向过程的均值函数逼近器 $\mu_\theta$ 来预测 $\tilde{\mu}_t$，或者通过修改其参数化来训练它预测 $\epsilon$（也有可能预测 $x_0$，但在早期实验中我们发现这会导致较差的样本质量）。我们已经展示了 $\epsilon$ 预测参数化既类似于Langevin动力学，也简化了扩散模型的变分界限，目标类似于去噪得分匹配。尽管如此，它只是 $p_\theta(x_{t-1} | x_t)$ 的另一种参数化，因此我们在第4节中通过消融实验验证了它的有效性，比较了预测 $\epsilon$ 和预测 $\tilde{\mu}_t$ 的效果。

### 3.3 数据缩放、反向过程解码器和 $L_0$

我们假设图像数据由 $\{0, 1, \dots, 255\}$ 的整数组成，并线性缩放到 $[-1, 1]$。这确保了神经网络的反向过程从标准正态先验 $p(x_T)$ 开始，对一致缩放的输入进行操作。为了获得离散对数似然，我们将反向过程的最后一项设为从高斯分布 $N(x_0; \mu_\theta(x_1, 1), \sigma_1^2 I)$ 推导出的独立离散解码器：

$$
p_\theta(x_0 | x_1) = \prod_{i=1}^{D} \int_{\delta^+(x_0^i)}^{\delta^-(x_0^i)} N(x; \mu_\theta^i(x_1, 1), \sigma_1^2) dx
\tag{13}
$$

其中，$D$ 是数据维度，$i$ 上标表示提取一个坐标。$\delta^+(x)$ 和 $\delta^-(x)$ 的定义如下：

$$
\delta^+(x) =
\begin{cases}
\infty, & \text{如果 } x = 1 \\
x + \frac{1}{255}, & \text{如果 } x < 1
\end{cases}
$$

$$
\delta^-(x) =
\begin{cases}
-\infty, & \text{如果 } x = -1 \\
x - \frac{1}{255}, & \text{如果 } x > -1
\end{cases}
$$

类似于VAE解码器和自回归模型中使用的离散化连续分布[34, 52]，我们的选择确保了变分边界是离散数据的无损编码长度，无需向数据中添加噪声或将缩放操作的雅可比矩阵纳入对数似然中。在采样结束时，我们无噪声地显示 $\mu_\theta(x_1, 1)$。

### 3.4 简化的训练目标

基于上面定义的反向过程和解码器，由公式(12)和(13)导出的变分边界可以对 $\theta$ 求导，适合用于训练。然而，我们发现使用以下变分边界的变体进行训练对样本质量有益（且实现起来更简单）：

$$
L_{\text{simple}}(\theta) := \mathbb{E}_{t,x_0,\epsilon} \left[ \left\| \epsilon - \epsilon_\theta \left( \sqrt{\bar{\alpha}_t} x_0 + \sqrt{1 - \bar{\alpha}_t} \epsilon, t \right) \right\|_2^2 \right]
\tag{14}
$$

其中，$t$ 在 $1$ 和 $T$ 之间均匀分布。$t = 1$ 的情况对应于公式(13)中离散解码器定义中的 $L_0$，其中积分由高斯概率密度函数与箱宽度的乘积近似，忽略 $\sigma_1^2$ 和边缘效应。$t > 1$ 的情况对应于公式(12)的未加权版本，类似于NCSN去噪得分匹配模型中使用的损失加权[55]。（由于正向过程的方差 $\beta_t$ 被固定，因此 $L_T$ 未出现。）算法1展示了使用该简化目标的完整训练过程。

由于我们的简化目标(14)忽略了公式(12)中的加权项，它是一种加权的变分边界，与标准变分边界[18, 22]相比，强调了重建的不同方面。特别是，我们在第4节中的扩散过程设置导致简化目标对与小 $t$ 对应的损失项进行下调。这些项训练网络去消除非常小的噪声，因此下调它们有助于网络专注于更难处理的大 $t$ 项的去噪任务。我们将在实验中看到，这种重新加权能够带来更好的样本质量。

## 4. 实验

我们在所有实验中将 $T = 1000$，以确保在采样过程中神经网络评估的次数与之前的工作[53, 55]相匹配。我们将正向过程的方差设置为从 $\beta_1 = 10^{-4}$ 到 $\beta_T = 0.02$ 线性递增的常数。这些常数相对于缩放至 $[-1, 1]$ 的数据较小，确保反向过程和正向过程具有大致相同的函数形式，同时保持在 $x_T$ 处的信噪比尽可能小（在我们的实验中，$L_T = D_{KL}(q(x_T | x_0) \| N(0, I)) \approx 10^{-5}$ 每维位数）。

为了表示反向过程，我们使用了类似于未遮掩的PixelCNN++ [52, 48] 的U-Net骨架，且全程使用了组归一化[66]。参数在时间上共享，时间通过Transformer的正弦位置嵌入[60] 传递给网络。我们在16 × 16特征图分辨率上使用自注意力[63, 60]。具体细节见附录B。

### 4.1 样本质量

表1显示了CIFAR10上的Inception分数、FID分数和负对数似然（无损编码长度）。我们的无条件模型在FID得分为3.17的情况下，样本质量优于文献中的大多数模型，包括类条件模型。我们的FID得分是相对于训练集计算的，这是标准做法；当我们相对于测试集计算时，得分为5.24，仍然优于文献中许多训练集的FID得分。

我们发现，使用真实的变分边界训练我们的模型比使用简化目标产生更好的编码长度，但后者提供了最佳的样本质量。请参阅图1（CIFAR10和CelebA-HQ 256×256样本）、图3和图4（LSUN 256×256样本[71]）以及附录D中的更多内容。

### 4.2 反向过程参数化与训练目标消融实验

在表2中，我们展示了反向过程参数化和训练目标（第3.2节）对样本质量的影响。我们发现，基线选项预测 $\tilde{\mu}$ 仅在训练于真实变分边界（而不是未加权的均方误差，即简化目标类似于公式(14)）时效果良好。我们还看到，学习反向过程的方差（通过在变分边界中加入参数化的对角线 $\Sigma_\theta(x_t)$）导致训练不稳定，并且样本质量较差，而使用固定方差的表现要好得多。我们提出的预测 $\epsilon$，在使用固定方差和变分边界训练时表现与预测 $\tilde{\mu}$ 相当，但在使用简化目标训练时表现要好得多。

### 4.3 渐进编码

表1还展示了我们CIFAR10模型的编码长度。训练集与测试集之间的差距最多为每维0.03位，与其他基于似然的模型报告的差距相当，这表明我们的扩散模型没有过拟合（见附录D中的最近邻可视化）。尽管如此，虽然我们的无损编码长度优于基于能量模型和使用退火重要性采样的得分匹配报告的较大估计值[11]，但它们在与其他类型的基于似然的生成模型的竞争中并不具备优势[7]。

由于我们的样本仍然具有高质量，我们得出结论：扩散模型具有使其成为优秀有损压缩器的归纳偏差。将变分边界项 $L_1 + \dots + L_T$ 视为速率，将 $L_0$ 视为失真，我们的CIFAR10模型在样本质量最高的情况下，速率为1.78 bits/dim，失真为1.97 bits/dim，相当于0到255量程上的均方根误差为0.95。超过一半的无损编码长度描述的是无法察觉的失真。

**渐进有损压缩** 我们可以通过引入类似于公式(5)形式的渐进有损编码来进一步探讨模型的速率-失真行为：参见算法3和4，它们假设有一个程序（如最小随机编码[19, 20]），可以用大约 $D_{KL}(q(x) \| p(x))$ 位的期望编码长度传输样本 $x \sim q(x)$，其中只有 $p$ 在接收方提前可用。当应用于 $x_0 \sim q(x_0)$ 时，算法3和4依次传输 $x_T, \dots, x_0$，其总期望编码长度等于公式(5)。接收方在任何时间 $t$ 都拥有完全的部分信息 $x_t$，并可以渐进估计：
$$
x_0 \approx \hat{x}_0 = \frac{x_t - \sqrt{1 - \bar{\alpha}_t} \epsilon_\theta(x_t)}{\sqrt{\bar{\alpha}_t}} 
\tag{15}
$$
根据公式(4)得出。（我们也可以考虑使用随机重构 $x_0 \sim p_\theta(x_0 | x_t)$，但这里不讨论，因为这会使失真更难评估。）图5展示了CIFAR10测试集上的速率-失真图。在每个时间点 $t$，失真通过均方根误差 $\sqrt{\frac{\|x_0 - \hat{x}_0\|_2^2}{D}}$ 计算，速率则计算为到目前为止接收到的比特的累积数。失真在速率-失真图的低速率区域急剧下降，表明大多数比特确实分配给了无法察觉的失真。

### 渐进生成

我们还运行了一个渐进无条件生成过程，该过程由随机比特的渐进解压缩给出。换句话说，我们通过算法2在反向过程中采样的同时，预测反向过程的结果 $\hat{x}_0$。图6和图10展示了反向过程中的 $\hat{x}_0$ 样本质量。大尺度图像特征首先出现，细节最后出现。图7展示了冻结不同 $t$ 时的随机预测 $x_0 \sim p_\theta(x_0 | x_t)$。当 $t$ 较小时，除了细节外的所有内容都被保留；当 $t$ 较大时，仅保留大尺度特征。这或许是概念压缩的提示[18]。

### 与自回归解码的联系

值得注意的是，变分边界(5)可以重写为：

$$
L = D_{KL}(q(x_T) \| p(x_T)) + \mathbb{E}_q \left[ \sum_{t \geq 1} D_{KL}(q(x_{t-1} | x_t) \| p_\theta(x_{t-1} | x_t)) \right] + H(x_0)
\tag{16}
$$

（推导见附录A）。现在，考虑将扩散过程的长度 $T$ 设为数据的维度，定义正向过程，使得 $q(x_t | x_0)$ 将所有概率质量集中在将前 $t$ 个坐标掩码掉的 $x_0$ 上（即 $q(x_t | x_{t-1})$ 掩码掉第 $t$ 个坐标），将 $p(x_T)$ 设置为一个空白图像的概率分布，并为了论证的目的，假设 $p_\theta(x_{t-1} | x_t)$ 是一个完全表达的条件分布。在这些选择下，$D_{KL}(q(x_T) \| p(x_T)) = 0$，最小化 $D_{KL}(q(x_{t-1} | x_t) \| p_\theta(x_{t-1} | x_t))$ 训练 $p_\theta$ 复制第 $t+1, \dots, T$ 坐标不变，并在给定第 $t+1, \dots, T$ 坐标的情况下预测第 $t$ 坐标。因此，使用这种特定扩散训练 $p_\theta$ 就是在训练一个自回归模型。

因此，我们可以将高斯扩散模型（公式2）解释为一种具有广义比特排序的自回归模型，该排序无法通过重新排列数据坐标来表达。之前的研究表明，这种重新排序引入了归纳偏差，影响了样本质量[38]，因此我们推测高斯扩散可能具有类似的作用，甚至效果更好，因为与掩码噪声相比，向图像中添加高斯噪声可能更加自然。此外，高斯扩散的长度不局限于等于数据的维度；例如，我们使用 $T = 1000$，这小于我们实验中的32×32×3或256×256×3图像的维度。可以通过缩短高斯扩散来加快采样速度，或者通过延长扩散来增强模型的表达能力。

### 4.4 插值

我们可以在潜在空间中对源图像 $x_0, x_0' \sim q(x_0)$ 进行插值，方法是使用 $q$ 作为随机编码器，从 $q(x_t|x_0)$ 中采样 $x_t, x_t' \sim q(x_t | x_0)$，然后将线性插值的潜在变量 $\bar{x}_t = (1 - \lambda)x_t + \lambda x_t'$ 解码为图像空间，得到 $\bar{x}_0 \sim p(x_0 | \bar{x}_t)$。实际上，我们使用反向过程去除线性插值的源图像的损坏版本中的伪影，如图8左所示。我们固定了不同 $\lambda$ 值的噪声，因此 $x_t$ 和 $x_t'$ 保持不变。图8右展示了 CelebA-HQ 256 × 256 图像（$t = 500$）的插值和重建。反向过程生成了高质量的重建结果，以及平滑变化的插值，插值中属性如姿势、肤色、发型、表情和背景平滑变化，但眼镜则没有变化。较大的 $t$ 导致更粗糙和更多样的插值，在 $t = 1000$ 时出现新样本（详见附录图9）。

## 5 相关工作

虽然扩散模型与流模型 [9, 46, 10, 32, 5, 16, 23] 和变分自编码器（VAE）[33, 47, 37] 相似，但扩散模型的设计使得 $q$ 无需参数，并且顶层潜变量 $x_T$ 与数据 $x_0$ 之间几乎没有互信息。我们使用 $\epsilon$-预测反向过程参数化建立了扩散模型与多重噪声级别下的去噪得分匹配以及用于采样的退火朗之万动力学之间的联系 [55, 56]。然而，扩散模型允许直接评估对数似然，训练过程通过变分推断显式训练朗之万动力学采样器（详见附录C）。这种联系也反向意味着某种加权形式的去噪得分匹配与通过变分推断训练朗之万动力学采样器是等价的。其他用于学习马尔可夫链转移算子的方法包括注入训练 [2]、变分回退 [15]、生成随机网络 [1]，以及其他方法 [50, 54, 36, 42, 35, 65]。

根据已知的得分匹配与基于能量的建模之间的联系，我们的工作可能对其他关于能量模型的最新研究产生影响 [67–69, 12, 70, 13, 11, 41, 17, 8]。我们随时间计算的速率-失真曲线类似于通过一次退火重要性采样运行计算的失真惩罚曲线 [24]。我们的渐进解码论点可以在卷积DRAW和相关模型中看到 [18, 40]，并且可能导致子规模排序或自回归模型采样策略的更一般设计 [38, 64]。

## 6 结论

我们展示了使用扩散模型生成的高质量图像样本，并发现了扩散模型与用于训练马尔可夫链的变分推断、去噪得分匹配和退火朗之万动力学（以及扩展到基于能量的模型）、自回归模型和渐进有损压缩之间的联系。由于扩散模型似乎对图像数据具有良好的归纳偏差，我们期待研究它们在其他数据模式中的实用性，以及它们作为其他类型生成模型和机器学习系统组件的潜力。

## 更广泛的影响

我们对扩散模型的研究与现有的其他类型深度生成模型的研究范围相似，例如改善GAN、流模型、自回归模型等的样本质量的努力。我们的论文代表了扩散模型成为这类技术家族中一个普遍有用工具的进展，因此可能会扩大生成模型对更广泛世界的影响。

不幸的是，生成模型有许多众所周知的恶意用途。样本生成技术可以用于制作高知名度人物的假图像和视频以用于政治目的。虽然在软件工具可用之前，假图像是通过手工创建的，但像我们这样的生成模型使这一过程变得更加容易。幸运的是，目前CNN生成的图像仍然存在一些微小的缺陷，可以被检测到 [62]，但生成模型的改进可能会使这一点变得更加困难。生成模型还反映了它们所训练的数据集中的偏见。由于许多大数据集是通过自动化系统从互联网收集的，因此很难去除这些偏见，尤其是在图像未标注的情况下。如果从这些数据集中训练的生成模型的样本在互联网上广泛传播，这些偏见只会进一步加剧。

另一方面，扩散模型可能对数据压缩有用，随着数据分辨率的提高和全球互联网流量的增加，数据压缩对于确保互联网的广泛可访问性可能至关重要。我们的工作可能为无标注原始数据的表征学习做出贡献，应用于从图像分类到强化学习的广泛下游任务，扩散模型也可能成为艺术、摄影和音乐中创造性用途的可行工具。